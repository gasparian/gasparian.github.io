<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ens on &amp;&gt; /dev/tux</title>
    <link>https://gasparian.github.io/en/</link>
    <description>Recent content in Ens on &amp;&gt; /dev/tux</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Oct 2023 19:12:58 +0200</lastBuildDate><atom:link href="https://gasparian.github.io/en/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>No-bullshit VPN on Raspberry PI</title>
      <link>https://gasparian.github.io/en/raspi-vpn/</link>
      <pubDate>Mon, 02 Oct 2023 19:12:58 +0200</pubDate>
      
      <guid>https://gasparian.github.io/en/raspi-vpn/</guid>
      <description>Disclaimer: All content on this blog is intended for educational purposes only. Only you is liable for any consequences resulting from your use of this information. You should always respect laws of your country.
Intro VPNs are primarily designed to create a secure and encrypted connection between your device and a remote server. This connection can be used to protect online privacy, hide your IP address, access geo-restricted content, and enhance security when connecting to the internet, especially on public Wi-Fi networks.</description>
    </item>
    
    <item>
      <title>cProfile 4 life</title>
      <link>https://gasparian.github.io/en/python-profiling/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://gasparian.github.io/en/python-profiling/</guid>
      <description>There are quite some profiling tools for Python, like popular scalene. But I like python for simplicity and really like to use some &amp;ldquo;default&amp;rdquo; tools from the standard python toolchain - so cProfile is my choice.
It doesn&amp;rsquo;t require fine-grained code annotation and very simple to use.
It shows stats on how much time is spent while executing certain functions. Really easy to work and interpret.
Run For example, the following command will run profiling on each function that is being run inside the main.</description>
    </item>
    
    <item>
      <title>OpenCV CUDA on ðŸ›ž`s</title>
      <link>https://gasparian.github.io/en/opencv-cuda/</link>
      <pubDate>Fri, 27 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://gasparian.github.io/en/opencv-cuda/</guid>
      <description>I think we all know opencv - itâ€™s a pretty old yet widely used and performant computer vision library with a lot of useful algorithms. One of the advantages of it - you can configure opencv how you want to get really nice performance gain. One of the ways - compile it to multiply matrices on GPUs to speed up both &amp;ldquo;old&amp;rdquo; CV filters (which are essentially convolutions) and use deep learning inference (yes, you can do it in opencv with the special module added).</description>
    </item>
    
    <item>
      <title>Tensorflow v1 vs v2 inference</title>
      <link>https://gasparian.github.io/en/tf1-vs-tf2/</link>
      <pubDate>Mon, 04 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gasparian.github.io/en/tf1-vs-tf2/</guid>
      <description>In tensorflow 1.0, you had to define your model as a graph, and run it using the following syntax:
with tf.Session(...) as sess: sess.run(...) This piece of code basically compiles a graph and puts it on the device that it should be executed on (CPU/GPU).
While compiling the graph, TensorFlow applies various optimizations, like running parallel branches in separate threads, etc. So, as a result, you could expect a better performance of the resulting model.</description>
    </item>
    
  </channel>
</rss>
